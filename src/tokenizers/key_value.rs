use crate::TResult;

#[derive(Debug, PartialEq, Eq, Clone)]
pub struct Tokenizer<'a, const C: char> {
    pub key: &'a str,
    pub value: &'a str,
}

impl<'a, const C: char> Tokenizer<'a, C> {
    pub fn tokenize(part: &'a str) -> TResult<'a, Self> {
        use crate::parser_utils::*;
        use nom::{bytes::complete::tag, sequence::preceded};

        let (rem, key) = preceded(tag(Self::prefix().as_str()), until_stopbreak_of(":"))(part)?;
        let (rem, value) = until_newline(rem)?;

        Ok((rem, (key, value).into()))
    }

    //TODO: this should be generated by a concat-related macro, but atm at stable this is not
    //possible, will come back once const generics expands on stable
    fn prefix() -> String {
        format!("{}=", C)
    }
}

impl<'a, const C: char> From<(&'a str, &'a str)> for Tokenizer<'a, C> {
    fn from((key, value): (&'a str, &'a str)) -> Self {
        Self { key, value }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn tokenizer() {
        let key_value = concat!("b=CT:128\r\nsomething");

        assert_eq!(
            Tokenizer::<'b'>::tokenize(key_value),
            Ok((
                "something",
                Tokenizer {
                    key: "CT",
                    value: "128",
                }
            )),
        );
    }
}
